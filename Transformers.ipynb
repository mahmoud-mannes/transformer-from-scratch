{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02dce27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from prepare import prepare_data\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2584093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters (setting the embedding_dim to be a multiple of d_key is ideal)\n",
    "embedding_dim = 64\n",
    "max_token = 8\n",
    "d_key = 16\n",
    "n_head = embedding_dim // d_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a8bfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_split(x,train,dev):\n",
    "    N = x.shape[0]\n",
    "    Ntr = int(N * train)\n",
    "    Ndev = int(N*dev)\n",
    "    ind = torch.randperm(Ntr)\n",
    "    data_tr = x[ind][:Ntr]\n",
    "    data_dev = x[ind][Ntr:Ntr+Ndev]\n",
    "    return data_tr,data_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4c20b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.device_count() else \"cpu\"\n",
    "full_data = prepare_data(\"input.txt\")\n",
    "data, vocab, encode, decode = torch.tensor(full_data[\"encoded_data\"], device=device), full_data[\"vocab\"], full_data[\"encode\"], full_data[\"decode\"]\n",
    "vocab_size = len(vocab)\n",
    "B = data.shape[0] // max_token\n",
    "ind = torch.randperm(n= data.shape[0] - max_token)[:B]\n",
    "ranges = ind.view(B,1) + torch.arange(max_token)\n",
    "data = data[ranges]\n",
    "data_tr,data_dev = train_dev_split(data,0.9,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40172510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  0, 28, 53, 50, 47, 62, 43],\n",
       "        [42, 45, 51, 43, 52, 58,  1, 54],\n",
       "        [57, 53, 52,  6,  1, 44, 39, 58],\n",
       "        [ 1, 51, 39, 49, 43,  1, 46, 47],\n",
       "        [ 1, 40, 53, 42, 63, 11,  0, 32],\n",
       "        [ 1, 42, 47, 57, 41, 53, 60, 43],\n",
       "        [54, 53, 53, 56,  1, 41, 46, 47],\n",
       "        [58, 46,  1, 39, 50, 51, 53, 57],\n",
       "        [51, 43, 58, 47, 51, 43, 57,  1],\n",
       "        [46,  0, 37, 53, 59,  1, 61, 43]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overfitting_data = data[:10]\n",
    "overfitting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9180bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_table = nn.Embedding(max_token,embedding_dim)\n",
    "    def forward(self,x):\n",
    "        return self.embedding_table(x) + self.pos_table(torch.arange(max_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c1b41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.keyM = nn.Linear(embedding_dim, d_key)\n",
    "        self.queryM = nn.Linear(embedding_dim, d_key)\n",
    "        self.valueM = nn.Linear(embedding_dim, d_key)\n",
    "    def forward(self,x):\n",
    "        Q = self.queryM(x)\n",
    "        K = self.keyM(x)\n",
    "        V = self.valueM(x)\n",
    "        scores = (Q @ K.permute(0,2,1)) / sqrt(d_key)\n",
    "        #Masking for attention\n",
    "        inp = torch.ones(max_token, max_token)  \n",
    "        mask = torch.tril(inp).bool()\n",
    "        scores = scores.masked_fill(~mask, float('-inf'))\n",
    "        #Attention\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        return attn @ V\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4feec7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head() for i in range(n_head)])\n",
    "    def forward(self,x):\n",
    "        res = []\n",
    "        for i in range(n_head):\n",
    "            res.append(self.heads[i](x))\n",
    "        return torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d66a4f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.tensor([1,0]),torch.tensor([1,2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "309b622a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0335e+00, -1.7547e-01,  4.1799e-01,  ...,  1.8663e+00,\n",
       "           1.1381e+00, -2.7055e-02],\n",
       "         [ 4.3373e-02,  2.1530e-01,  6.8400e-01,  ...,  8.8471e-01,\n",
       "          -8.3931e-01, -3.8434e-01],\n",
       "         [-1.0261e-01,  1.0107e-01,  2.4153e-01,  ...,  6.4124e-01,\n",
       "          -2.8775e-02, -2.2576e-01],\n",
       "         ...,\n",
       "         [ 2.1603e-01,  9.1425e-02, -1.0358e-01,  ...,  2.4007e-01,\n",
       "           1.3572e-01, -2.5886e-01],\n",
       "         [ 2.4690e-01,  2.5743e-01, -3.2803e-02,  ...,  7.2757e-01,\n",
       "           4.9256e-01, -4.4815e-01],\n",
       "         [ 5.9723e-01,  2.6753e-02, -1.0992e-01,  ...,  4.3336e-01,\n",
       "           3.4864e-01, -3.2583e-01]],\n",
       "\n",
       "        [[ 2.2754e-01, -7.1095e-02, -2.0852e-01,  ...,  1.2240e+00,\n",
       "           1.2141e+00,  1.2294e+00],\n",
       "         [ 1.8762e-02,  6.1646e-03,  7.6440e-01,  ...,  7.4719e-01,\n",
       "           5.5001e-01,  4.1232e-01],\n",
       "         [ 7.3700e-02, -9.3607e-02, -2.7212e-02,  ...,  8.0316e-01,\n",
       "           7.0005e-01,  8.6644e-01],\n",
       "         ...,\n",
       "         [ 2.6801e-01,  2.1178e-01,  4.0629e-01,  ...,  1.0553e-01,\n",
       "          -2.3817e-02,  1.0074e-01],\n",
       "         [ 2.9347e-01,  2.5281e-01,  1.5810e-01,  ..., -1.6892e-01,\n",
       "          -3.4472e-01,  3.2233e-02],\n",
       "         [ 1.5546e-01,  9.4073e-02,  3.2260e-01,  ...,  3.2939e-02,\n",
       "           5.3282e-02,  6.8776e-02]],\n",
       "\n",
       "        [[ 8.9135e-01,  9.1661e-01, -1.2810e-01,  ...,  9.9942e-01,\n",
       "           1.2351e+00,  5.2935e-01],\n",
       "         [-5.1823e-01,  3.2854e-01,  9.7982e-01,  ..., -2.5702e-01,\n",
       "          -9.5316e-01, -2.7911e-01],\n",
       "         [-5.6516e-02,  4.2275e-01,  5.7193e-01,  ..., -2.1191e-03,\n",
       "          -2.2250e-01,  2.0903e-02],\n",
       "         ...,\n",
       "         [ 3.3788e-01,  1.3160e-01,  1.3249e-01,  ..., -1.4298e-01,\n",
       "          -2.1442e-02,  4.9212e-02],\n",
       "         [ 5.4157e-02,  4.7644e-02,  4.3910e-01,  ..., -2.5453e-01,\n",
       "           9.0186e-02, -2.0516e-03],\n",
       "         [-1.0171e-01,  6.0610e-01,  3.1000e-01,  ..., -1.3548e-02,\n",
       "          -2.0420e-01, -4.8514e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.8228e+00,  6.6448e-01, -9.1522e-02,  ...,  1.9815e+00,\n",
       "           6.5915e-01,  4.6721e-02],\n",
       "         [ 1.0145e+00,  6.0114e-01,  5.4451e-01,  ...,  8.4156e-01,\n",
       "          -5.1279e-01, -2.3596e-01],\n",
       "         [ 2.4891e-01,  3.9871e-01,  3.3732e-01,  ..., -7.8797e-02,\n",
       "          -8.7911e-01,  3.4197e-03],\n",
       "         ...,\n",
       "         [ 7.1692e-01,  5.7165e-01, -7.2891e-02,  ..., -5.4810e-02,\n",
       "          -2.7918e-02, -2.5873e-01],\n",
       "         [ 4.0788e-01,  4.0462e-01,  5.1671e-02,  ...,  2.2552e-01,\n",
       "          -4.9679e-01, -5.4753e-04],\n",
       "         [ 5.1990e-01,  3.2495e-01, -4.5688e-02,  ...,  1.0393e-01,\n",
       "          -1.7261e-01, -1.7973e-02]],\n",
       "\n",
       "        [[ 1.1668e+00,  1.4706e-01,  1.8742e-01,  ...,  1.3970e+00,\n",
       "           4.0351e-01,  2.1344e-01],\n",
       "         [-2.9086e-01,  5.2623e-01,  6.8406e-01,  ..., -1.4472e-01,\n",
       "          -1.0390e+00,  4.3221e-01],\n",
       "         [-1.1617e-01,  4.8929e-01,  5.5211e-01,  ..., -8.7016e-02,\n",
       "          -9.6162e-01,  3.9247e-01],\n",
       "         ...,\n",
       "         [ 3.9919e-01,  3.4230e-01, -5.2390e-02,  ...,  2.0658e-02,\n",
       "          -6.3184e-01,  6.8209e-02],\n",
       "         [ 4.4078e-01,  3.9227e-01, -2.1001e-01,  ...,  2.0989e-02,\n",
       "          -4.4010e-01,  1.8188e-01],\n",
       "         [ 1.5426e-01,  4.9129e-01,  2.8704e-02,  ..., -4.1025e-02,\n",
       "          -4.8435e-01,  1.6245e-01]],\n",
       "\n",
       "        [[ 1.5250e+00,  1.0133e-01, -2.9871e-01,  ...,  1.3902e+00,\n",
       "           1.0239e+00,  2.0131e-02],\n",
       "         [ 7.7959e-02,  3.1813e-01,  5.3006e-01,  ...,  6.8064e-01,\n",
       "          -1.0414e+00, -4.0407e-01],\n",
       "         [ 3.5146e-01,  1.3886e-01,  3.1280e-01,  ...,  5.2478e-01,\n",
       "          -5.7131e-01, -3.3284e-01],\n",
       "         ...,\n",
       "         [ 2.4458e-01,  1.4559e-01,  4.0091e-02,  ..., -5.0333e-01,\n",
       "          -5.6950e-01, -2.7720e-01],\n",
       "         [-2.9178e-01,  5.2290e-01,  2.4477e-01,  ...,  1.4929e-01,\n",
       "           5.3448e-02, -1.4444e-01],\n",
       "         [ 3.3178e-01,  1.8250e-01,  9.6058e-02,  ..., -4.5020e-02,\n",
       "          -1.5996e-01, -1.0945e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = Transformer()\n",
    "embedded = emb(overfitting_data)\n",
    "single_head = Head()\n",
    "current = single_head(embedded)\n",
    "current"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
